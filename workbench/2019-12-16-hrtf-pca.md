---
title: Applying PCA to HRTFs
date: 2019-12-16
parent: Workbench
layout: default
nav_order: 3
---

# Applying PCA to HRTFs

I wrote a quick write-up on using PCA to an HRTF database! You can find the PDF here: [Visualization and principal component analysis from a head-related transfer function database](https://github.com/alextongue/alextongue.github.io/blob/master/workbench/resources/Tung_HRTFPCA.pdf).

It was for a pretty open-ended class project about data analysis, and I thought it would be useful to wrap my head around some dimensionality reduction. There's nothing novel in this paper, but you could call this an implementation of [Kistler & Wightman's JASA entry](https://doi.org/10.1121/1.402444).

The quick and dirty summary is that for each subject's HRTF, the unique per-subject, per-ear mean was subtracted, and then the grand mean of resulting functions was subtracted. I then took the covariance of the final set and used its most heavily-weighted eigenvectors as bases to transform the original HRTFs. Here are some of my figures:

<figure>
  <img src="https://github.com/alextongue/alextongue.github.io/blob/master/workbench/resources/hrtfpca/itd_iid.png?raw=true">
  <figcaption> Figure 1: Some ITD and IID slices</figcaption>
</figure>
  
<figure>
  <img src="https://github.com/alextongue/alextongue.github.io/blob/master/workbench/resources/hrtfpca/hrtf_dtf.png?raw=true">
  <figcaption> Figure 2: Preprocessing done to HRTF's (colloquially Directional Transfer Functions, or DTFs</figcaption>
</figure>

<figure>
  <img src="https://github.com/alextongue/alextongue.github.io/blob/master/workbench/resources/hrtfpca/covar_corre.png?raw=true">
  <figcaption>Figure 3: Covariance and correlation matrices of the mean-subtracted HRTFs</figcaption>
</figure>

<figure>
    <img src="https://github.com/alextongue/alextongue.github.io/blob/master/workbench/resources/hrtfpca/components.png?raw=true" width="400">
  <figcaption>Figure 4: The first five orthogonal bases that can be used to decompose HRTFs</figcaption>
</figure>

<figure>
  <img src="https://github.com/alextongue/alextongue.github.io/blob/master/workbench/resources/hrtfpca/hrtf2_loss.png?raw=true">
  <figcaption>Figure 5: A reconstruction of an HRTF and loss functions</figcaption>
</figure>


I used to be annoyed because math equations weren't written impeccably with consistent subscripting and subspaces. I realized that it's really hard to keep track without getting lost in a jumble of letters.